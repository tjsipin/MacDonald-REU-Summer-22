'te_forest', 'enn_mn_forest','Population','Year'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
data$Year <- as.numeric(data$Year)
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_70_temp <- testing(split)
Index_temp_70 <- as.numeric(rownames(data_test_70_temp))
data_test_70 <-  (aad %>%
dplyr::select(c(colnames(data_test_70_temp))))[Index_temp_70,]%>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
data_test_70$pland_forest <- ifelse(is.na(data_test_70$pland_forest), 0, data_test_70$pland_forest)
data_test_70$te_forest <- ifelse(is.na(data_test_70$te_forest), 0, data_test_70$te_forest)
data_test_70$enn_mn_forest <- ifelse(is.na(data_test_70$enn_mn_forest), 0, data_test_70$enn_mn_forest)
data_test_70$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_70$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + AvgRad + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'models/stacking/svm_res_later_CL_classif_70')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'models/stacking/xgb_res_later_CL_classif_70')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'models/stacking/rf_res_later_CL_classif_70')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'models/stacking/nb_res_later_CL_classif_70')
load(file = 'models/stacking/svm_res_later_CL_classif_70')
load(file = 'models/stacking/xgb_res_later_CL_classif_70')
load(file = 'models/stacking/rf_res_later_CL_classif_70')
load(file = 'models/stacking/nb_res_later_CL_classif_70')
data_st_70 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_70, file = 'models/stacking/data_st_later_CL_classif_70')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_70 <-
data_st_70 %>%
blend_predictions()
model_st_70 <-
model_st_70 %>%
fit_members()
save(model_st_70, file = 'models/stacking/model_st_later_CL_classif_70')
set.seed(123)
data_test_70 <- testing(split)
data_test_70 <-
data_test_70 %>%
bind_cols(predict(model_st_70, .))
save(data_test_70, file = 'models/stacking/data_test_later_CL_classif_70')
# confusion matrix for stacks
conf_mat_later_CL_classif_70 <- caret::confusionMatrix(data = data_test_70$.pred_class,
reference = data_test_70$Cutaneous.Leishmaniasis,
positive = '1')
conf_mat_later_CL_classif_70
save(conf_mat_later_CL_classif_70, file = 'models/stacking/conf_mat_later_CL_classif_70')
# confusion matrix for base models
member_preds <-
data_test_70 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_70,
data_test_70,
members = TRUE
)
)
load(file = 'models/stacking/conf_mat_later_CL_classif_30')
load(file = 'models/stacking/conf_mat_later_CL_classif_40')
load(file = 'models/stacking/conf_mat_later_CL_classif_50')
load(file = 'models/stacking/conf_mat_later_CL_classif_60')
load(file = 'models/stacking/conf_mat_later_CL_classif_70')
conf_mat_later_CL_classif_30
conf_mat_later_CL_classif_40
conf_mat_later_CL_classif_50
conf_mat_later_CL_classif_60
conf_mat_later_CL_classif_70
library(tidyverse)
library(pROC)
library(dplyr)
library(ggplot2)
library(plotROC)
load(file = 'models/stacking/data_test_later_CL_classif_30')
load(file = 'models/stacking/data_test_later_CL_classif_40')
load(file = 'models/stacking/data_test_later_CL_classif_50')
load(file = 'models/stacking/data_test_later_CL_classif_60')
load(file = 'models/stacking/data_test_later_CL_classif_70')
roc_30 <- roc(data_test_30$Cutaneous.Leishmaniasis,
data_test_30$.pred_class %>% as.numeric(),
print.auc = T, main = "AUC's of Percentiles in Later Data")
roc_40 <- roc(data_test_40$Cutaneous.Leishmaniasis,
data_test_40$.pred_class %>% as.ordered(),
print.auc = T)
roc_50 <- roc(data_test_50$Cutaneous.Leishmaniasis,
data_test_50$.pred_class %>% as.ordered(),
print.auc = T)
roc_60 <- roc(data_test_60$Cutaneous.Leishmaniasis,
data_test_60$.pred_class %>% as.ordered())
roc_70 <- roc(data_test_70$Cutaneous.Leishmaniasis,
data_test_70$.pred_class %>% as.ordered())
roc_list <- list('30th percentile' = roc_30,
'40th percentile' = roc_40,
'50th percentile' = roc_50,
'60th percentile' = roc_60,
'70th percentile' = roc_70)
# extract AUC
data.auc <- roc_list %>%
map(~tibble(AUC = .x$auc)) %>%
bind_rows(.id = 'name')
# generate labels
data.labels <- data.auc %>%
mutate(label_long = paste0(name, ' , AUC = ',
paste(round(AUC,2))),
label_AUC = paste0('AUC = ',
paste(round(AUC,2))))
pROC::ggroc(roc_list,
legacy.axes = F) +
scale_color_discrete(labels = data.labels$label_long)
# to get true levels of CL again
data <- read_csv('models/data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.4))[[1]] # PARAMETER
data <- data %>%
filter(Year > 2013) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'AvgRad', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
set.seed(123)
split_t <- initial_split(data)
training_t <- training(split_t)
testing_t <- testing(split_t)
mis_40 <- data_test_40 %>%
mutate(CL = testing_t$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
mis_40 <- data_test_40 %>%
mutate(CL = data_test_40_temp$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
knitr::opts_chunk$set(echo = T, cache = T, eval = T, results = 'show')
set.seed(123)
library(tidyverse)
library(tidymodels)
library(stacks)
aad <- read_csv('models/data/aad.csv')
load('./data/imp')
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
set.seed(123)
# load and split the later data using imputed data
load('./data/imp')
aad <- read_csv('models/data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.4))[[1]] # PARAMETER
data <- data %>%
filter(Year > 2013) %>%
filter(Year < 2018) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'AvgRad', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population','Year'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
data$Year <- as.numeric(data$Year)
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_40_temp <- testing(split)
Index_temp_40 <- as.numeric(rownames(data_test_40_temp))
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[Index_temp_40,] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
data_test_40$pland_forest <- ifelse(is.na(data_test_40$pland_forest), 0, data_test_40$pland_forest)
data_test_40$te_forest <- ifelse(is.na(data_test_40$te_forest), 0, data_test_40$te_forest)
data_test_40$enn_mn_forest <- ifelse(is.na(data_test_40$enn_mn_forest), 0, data_test_40$enn_mn_forest)
data_test_40$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_40$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + AvgRad + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'models/stacking/svm_res_later_CL_classif_40')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'models/stacking/xgb_res_later_CL_classif_40')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'models/stacking/rf_res_later_CL_classif_40')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'models/stacking/nb_res_later_CL_classif_40')
load(file = 'models/stacking/svm_res_later_CL_classif_40')
load(file = 'models/stacking/xgb_res_later_CL_classif_40')
load(file = 'models/stacking/rf_res_later_CL_classif_40')
load(file = 'models/stacking/nb_res_later_CL_classif_40')
data_st_40 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_40, file = 'models/stacking/data_st_later_CL_classif_40')
load('models/stacking/data_st_later_CL_classif_40')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensemble member
model_st_40 <-
data_st_40 %>%
blend_predictions()
model_st_40 <-
model_st_40 %>%
fit_members()
save(model_st_40, file = 'models/stacking/model_st_later_CL_classif_40')
load('models/stacking/model_st_later_CL_classif_40')
data_test_40 <-
data_test_40 %>%
bind_cols(predict(model_st_40, .))
save(data_test_40, file = 'models/stacking/data_test_later_CL_classif_40')
load(file = 'models/stacking/data_test_later_CL_classif_40')
# confusion matrix for stacks
conf_mat_later_CL_classif_40 <- caret::confusionMatrix(data = data_test_40$.pred_class, reference = data_test_40$Cutaneous.Leishmaniasis,positive = '1')
conf_mat_later_CL_classif_40
save(conf_mat_later_CL_classif_40, file = 'models/stacking/conf_mat_later_CL_classif_40')
# confusion matrix for base models
member_preds <-
data_test_40 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_40,
data_test_40,
members = TRUE
)
)
