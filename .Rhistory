set_mode('classification') %>%
fit(CL ~ ., data = train_cat %>% select(-c(Name, Code, Year, Month, EVI)))
set.seed(123)
# rf_wf <- workflow() %>%
#   add_model(rf_model) %>%
#   add_recipe(rf_recipe) %>%
#   fit(train_cat)
testing_data_later_50 <- rf_model %>%
predict(rf_testing) %>%
bind_cols(rf_testing)
confusionMatrix(data = testing_data_later$.pred_class, reference = testing_data_later$CL)
## 60
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.6))[[1]]
data_cat <- data %>%
mutate(CL = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor())
set.seed(123)
# data_sample <- sample_n(data, size = nrow(data) * 0.7)
split_cat <- initial_split(data_cat, prop = 0.7, strata = CL)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)
library(tidyverse)
library(tidymodels)
rf_recipe <-
recipe(
CL ~ Population + LST_Day + NDVI + Precip + AvgRad + SWOccurrence +
pland_forest + enn_mn_forest + te_forest + area_mn_forest,
data = train_cat) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test_cat)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 3,
trees = 700) %>%
set_engine('ranger', importance = 'impurity',
seed = 123) %>%
set_mode('classification') %>%
fit(CL ~ ., data = train_cat %>% select(-c(Name, Code, Year, Month, EVI)))
set.seed(123)
# rf_wf <- workflow() %>%
#   add_model(rf_model) %>%
#   add_recipe(rf_recipe) %>%
#   fit(train_cat)
testing_data_later_60 <- rf_model %>%
predict(rf_testing) %>%
bind_cols(rf_testing)
confusionMatrix(data = testing_data_later$.pred_class, reference = testing_data_later$CL)
## 70
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.7))[[1]]
data_cat <- data %>%
mutate(CL = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor())
set.seed(123)
# data_sample <- sample_n(data, size = nrow(data) * 0.7)
split_cat <- initial_split(data_cat, prop = 0.7, strata = CL)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)
library(tidyverse)
library(tidymodels)
rf_recipe <-
recipe(
CL ~ Population + LST_Day + NDVI + Precip + AvgRad + SWOccurrence +
pland_forest + enn_mn_forest + te_forest + area_mn_forest,
data = train_cat) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test_cat)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 3,
trees = 700) %>%
set_engine('ranger', importance = 'impurity',
seed = 123) %>%
set_mode('classification') %>%
fit(CL ~ ., data = train_cat %>% select(-c(Name, Code, Year, Month, EVI)))
set.seed(123)
# rf_wf <- workflow() %>%
#   add_model(rf_model) %>%
#   add_recipe(rf_recipe) %>%
#   fit(train_cat)
testing_data_later_70 <- rf_model %>%
predict(rf_testing) %>%
bind_cols(rf_testing)
confusionMatrix(data = testing_data_later$.pred_class, reference = testing_data_later$CL)
quantile
quantile <- (quantile_data$CL %>%
quantile(.3))[[1]]
quantile
## 30
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.3))[[1]]
quantile
data_cat <- data %>%
mutate(CL = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor())
data_cat
## 30
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.3))[[1]]
data_cat <- data %>%
mutate(CL = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor())
set.seed(123)
# data_sample <- sample_n(data, size = nrow(data) * 0.7)
split_cat <- initial_split(data_cat, prop = 0.7, strata = CL)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)
library(tidyverse)
library(tidymodels)
rf_recipe <-
recipe(
CL ~ Population + LST_Day + NDVI + Precip + AvgRad + SWOccurrence +
pland_forest + enn_mn_forest + te_forest + area_mn_forest,
data = train_cat) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test_cat)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 3,
trees = 700) %>%
set_engine('ranger', importance = 'impurity',
seed = 123) %>%
set_mode('classification') %>%
fit(CL ~ ., data = train_cat %>% select(-c(Name, Code, Year, Month, EVI)))
knitr::opts_chunk$set(echo = TRUE)
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'negbinom') %>%
summary
library(randomForest)
library(ggplot2)
library(finalfit)
library(dplyr)
library(naniar)
library(readr)
library(tidyverse)
library(caret)
library(readr)
library(dplyr)
library(mlbench)
library(rsample)
library(tidyverse)
library(tidymodels)
diff_data <- read_csv('../data/diff_data.csv')
data <- diff_data %>%
select(-c(...1)) %>%
filter(Year %in% c(2014, 2015, 2016, 2017)) %>%
filter(CL > 0)
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.4))[[1]]
data_cat <- data %>%
mutate(CL_cat = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor()) %>%
select(-c(Name, Year, Code, Country, TEMP_pland_forest, TEMP_te_forest, TEMP_enn_mn_forest, TEMP_area_mn_forest))
# data partitioning
set.seed(123)
split_cat <- initial_split(data_cat, prop = 0.7, strata = CL_cat)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)
rf_recipe <-
recipe(
CL ~ .,
data = train_cat) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test_cat)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 7,
trees = 700) %>%
set_engine('ranger', importance = 'permutation',
seed = 123, quantreg = T) %>%
set_mode('regression')
preds_bind <- function(data_fit, lower = 0.1, upper = 0.9) {
predict(
rf_wf$fit$fit$fit,
extract_recipe(rf_wf) %>%
bake(data_fit),
type = 'quantiles',
quantiles = c(lower, upper, 0.50)
) %>%
with(predictions) %>%
as_tibble() %>%
set_names(paste0('.pred', c('_lower', '_upper', ''))) %>%
# mutate(across(contains('.pred'), ~10^.x)) %>%
bind_cols(data_fit) %>%
select(contains('.pred'), CL, Month, CL_cat, Population,
LST_Day, LST_Night, NDVI, EVI, Precip, AvgRad, SWOccurrence,
Muni_TotalArea, TEMP_diff_pland_forest, TEMP_diff_area_mn_forest,
TEMP_diff_enn_mn_forest, TEMP_diff_te_forest,
pland_forest, area_mn_forest, enn_mn_forest, te_forest)
}
rf_wf <- workflow() %>%
add_model(rf_model) %>%
add_recipe(rf_recipe) %>%
fit(train_cat)
rf_preds_test <- preds_bind(test_cat)
set.seed(123)
rf_preds_test %>%
mutate(pred_interval = cut_number(CL, n = 0.01)) %>%
group_by(pred_interval) %>%
sample_n(1000) %>%
ggplot(aes(x = .pred)) +
geom_point(aes(y = .pred, color = 'prediction interval')) +
geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper, color = 'prediction interval')) +
geom_point(aes(y = CL, color = 'actuals'),
alpha = 0.7) +
scale_x_log10() +
scale_y_log10()
rf_preds_train <- preds_bind(train_cat)
bind_rows(
mape(rf_preds_train, CL, .pred),
mape(rf_preds_test, CL, .pred)) %>%
mutate(dataset = c('training', 'holdout')) %>%
gt::gt() %>%
gt::fmt_number('.estimate', decimals = 1)
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'negbinom') %>%
summary
?glm
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'nb') %>%
summary
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'quasibinomial') %>%
summary
library(randomForest)
library(ggplot2)
library(finalfit)
library(dplyr)
library(naniar)
library(readr)
library(tidyverse)
library(caret)
library(readr)
library(dplyr)
library(mlbench)
library(rsample)
library(tidyverse)
library(tidymodels)
diff_data <- read_csv('../data/diff_data.csv')
data <- diff_data %>%
select(-c(...1)) %>%
filter(Year %in% c(2014, 2015, 2016, 2017)) %>%
filter(CL > 0)
quantile_data <- data %>%
filter(CL > 0) %>%
select(CL)
quantile <- (quantile_data$CL %>%
quantile(.4))[[1]]
data_cat <- data %>%
mutate(CL_cat = case_when(CL < quantile ~ 'low',
CL >= quantile ~ 'high') %>%
as_factor()) %>%
select(-c(Name, Year, Code, Country, TEMP_pland_forest, TEMP_te_forest, TEMP_enn_mn_forest, TEMP_area_mn_forest))
# data partitioning
set.seed(123)
split_cat <- initial_split(data_cat, prop = 0.7, strata = CL_cat)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)
## 40
library(tidyverse)
library(tidymodels)
rf_recipe <-
recipe(
CL ~ .,
data = train_cat) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test_cat)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 7,
trees = 700) %>%
set_engine('ranger', importance = 'impurity',
seed = 123) %>%
set_mode('classification') %>%
fit(CL_cat ~ ., data = train_cat %>% select(-c(CL)))
set.seed(123)
# rf_wf <- workflow() %>%
#   add_model(rf_model) %>%
#   add_recipe(rf_recipe) %>%
#   fit(train_cat)
testing_data_later_40 <- rf_model %>%
predict(rf_testing) %>%
bind_cols(predict(rf_model, rf_testing, type = 'prob')) %>%
bind_cols(rf_testing)
confusionMatrix(data = testing_data_later_40$.pred_class, reference = testing_data_later_40$CL_cat)
target_as_int <- as.integer(test_cat$CL_cont)
explainer_rf <- DALEX::explain(model = rf_model,
data = test_cat %>%
select(-c(CL_cont)),
y = target_as_int,
label = 'Random Forest')
target_as_int <- as.integer(test_cat$CL_cat)
explainer_rf <- DALEX::explain(model = rf_model,
data = test_cat %>%
select(-c(CL_cat)),
y = target_as_int,
label = 'Random Forest')
save(explainer_rf, file = 'explainer_rf_CL_monthly_diff')
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'quasibinomial') %>%
summary
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'quasibinomial')
glm(CL ~ . - CL_cat - .pred_class - NDVI - LST_Day - Muni_TotalArea -
enn_mn_forest - TEMP_diff_pland_forest - TEMP_diff_enn_mn_forest -
Population - AvgRad - TEMP_diff_te_forest - Precip -
SWOccurrence - TEMP_diff_area_mn_forest - .pred_high, data = testing_data_later_40,
family = 'quasibinomial') %>%
plot
split <- initial_split(testing_data_later_40, prop = 0.7)
training <- training(split)
testing <- testing(split)
training
training %>% names
?case_when
testing_data_later_40
testing_data_later_40
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
step_corr(all_predictors()) %>%
step_normalize(all_predictors(), -all_outcomes()) %>%
prep()
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
step_corr(all_predictors()) %>%
prep()
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test)
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
prep()
rf_testing <- rf_recipe %>%
bake(test)
training %>% colnames
rf_testing <- rf_recipe %>%
bake(test)
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_testing <- rf_recipe %>%
bake(testing)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 5,
trees = 200) %>%
set_engine('ranger', importance = 'impurity',
seed = 123, quantreg = TRUE) %>%
set_mode('regression')
training %>% names
rf_wf <- workflow() %>%
add_model(rf_model) %>%
add_recipe(rf_recipe) %>%
fit(training)
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
prep()
rf_testing <- rf_recipe %>%
bake(testing)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 5,
trees = 200) %>%
set_engine('ranger', importance = 'permutation',
seed = 123, quantreg = TRUE) %>%
set_mode('regression')
rf_wf <- workflow() %>%
add_model(rf_model) %>%
add_recipe(rf_recipe) %>%
fit(training)
prob_data <- testing_data_later_40 %>%
mutate(pred_prob = 2*.pred_high - 1) %>%
select(-c(.pred_class, .pred_low, .pred_high))
split <- initial_split(prob_data, prop = 0.7, CL)
training <- training(split)
testing <- testing(split)
rf_recipe <-
recipe(
CL ~ .,
data = training) %>%
prep()
rf_testing <- rf_recipe %>%
bake(testing)
rf_training <- juice(rf_recipe)
rf_model <- rand_forest(mtry = 5,
trees = 200) %>%
set_engine('ranger', importance = 'permutation',
seed = 123, quantreg = TRUE) %>%
set_mode('regression')
rf_wf <- workflow() %>%
add_model(rf_model) %>%
add_recipe(rf_recipe) %>%
fit(training)
preds_bind <- function(data_fit, lower = 0.1, upper = 0.9) {
predict(
rf_wf$fit$fit$fit,
extract_recipe(rf_wf) %>%
bake(data_fit),
type = 'quantiles',
quantiles = c(lower, upper, 0.50)
) %>%
with(predictions) %>%
as_tibble() %>%
set_names(paste0('.pred', c('_lower', '_upper', ''))) %>%
# mutate(across(contains('.pred'), ~10^.x)) %>%
bind_cols(data_fit) %>%
select(contains('.pred'), CL, Population,
LST_Day, NDVI, EVI, Precip, AvgRad, SWOccurrence,
pland_forest, area_mn_forest, enn_mn_forest, te_forest)
}
rf_preds_test <- preds_bind(testing)
set.seed(123)
rf_preds_test %>%
mutate(pred_interval = cut_number(CL, n = 0.01)) %>%
group_by(pred_interval) %>%
sample_n(1000) %>%
ggplot(aes(x = .pred)) +
geom_point(aes(y = .pred, color = 'prediction interval')) +
geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper, color = 'prediction interval')) +
geom_point(aes(y = CL, color = 'actuals'),
alpha = 0.7) +
scale_x_log10() +
scale_y_log10()
rf_preds_train <- preds_bind(training)
bind_rows(
mape(rf_preds_train, CL, .pred),
mape(rf_preds_test, CL, .pred)) %>%
mutate(dataset = c('training', 'holdout')) %>%
gt::gt() %>%
gt::fmt_number('.estimate', decimals = 1)
