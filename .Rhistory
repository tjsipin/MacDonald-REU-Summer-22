add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_50, file = 'data_stacks/noNA_data_st_early_CL_classif_50')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_50 <-
data_st_50 %>%
blend_predictions()
model_st_50 <-
model_st_50 %>%
fit_members()
save(model_st_50, file = 'model_stacks/noNA_model_st_early_CL_classif_50')
# load('model_stacks/noNA_model_st_early_CL_classif_50')
set.seed(123)
data_test_50 <-
data_test_50 %>%
bind_cols(predict(model_st_50, .))
save(data_test_50, file = 'data_tests/noNA_data_test_early_CL_classif_50')
# confusion matrix for stacks
conf_mat_early_CL_classif_50 <- caret::confusionMatrix(data = data_test_50$.pred_class,
reference = data_test_50$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_50, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# confusion matrix for base models
member_preds <-
data_test_50 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_50,
data_test_50,
members = TRUE
)
)
rm(list=ls())
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
# load and split the early data using imputed data
load('../../data/imp')
aad <- read.csv('../data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.6))[[1]] # PARAMETER
data <- data %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
split <- initial_split(data)
data_train <- training(split)
data_test_60_temp <- testing(split)
data_test_60 <-  (aad %>%
select(c(colnames(data_test_60_temp))))[data_test_60_temp %>% rownames(),] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))%>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data_test_60$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_60$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + StableLights + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(sensitivity, accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'base_models/noNA_svm_res_early_CL_classif_60')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'base_models/noNA_xgb_res_early_CL_classif_60')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'base_models/noNA_rf_res_early_CL_classif_60')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'base_models/noNA_nb_res_early_CL_classif_60')
# load(file = 'base_models/noNA_svm_res_early_CL_classif_60')
# load(file = 'base_models/noNA_xgb_res_early_CL_classif_60')
# load(file = 'base_models/noNA_rf_res_early_CL_classif_60')
# load(file = 'base_models/noNA_nb_res_early_CL_classif_60')
data_st_60 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_60, file = 'data_stacks/noNA_data_st_early_CL_classif_60')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_60 <-
data_st_60 %>%
blend_predictions()
model_st_60 <-
model_st_60 %>%
fit_members()
save(model_st_60, file = 'model_stacks/noNA_model_st_early_CL_classif_60')
# load('model_stacks/noNA_model_st_early_CL_classif_60')
set.seed(123)
data_test_60 <-
data_test_60 %>%
bind_cols(predict(model_st_60, .))
save(data_test_60, file = 'data_tests/noNA_data_test_early_CL_classif_60')
# confusion matrix for stacks
conf_mat_early_CL_classif_60 <- caret::confusionMatrix(data = data_test_60$.pred_class,
reference = data_test_60$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_60, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# confusion matrix for base models
member_preds <-
data_test_60 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_60,
data_test_60,
members = TRUE
)
)
data_test_70 %>% tail()
rm(list=ls())
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
# load and split the early data using imputed data
load('../../data/imp')
aad <- read.csv('../data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.7))[[1]] # PARAMETER
data <- data %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
split <- initial_split(data)
data_train <- training(split)
data_test_70_temp <- testing(split)
data_test_70 <-  (aad %>%
select(c(colnames(data_test_70_temp))))[data_test_70_temp %>% rownames(),] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))%>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data_test_70$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_70$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + StableLights + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(sensitivity, accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'base_models/noNA_svm_res_early_CL_classif_70')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'base_models/noNA_xgb_res_early_CL_classif_70')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'base_models/noNA_rf_res_early_CL_classif_70')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'base_models/noNA_nb_res_early_CL_classif_70')
# load(file = 'base_models/noNA_svm_res_early_CL_classif_70')
# load(file = 'base_models/noNA_xgb_res_early_CL_classif_70')
# load(file = 'base_models/noNA_rf_res_early_CL_classif_70')
# load(file = 'base_models/noNA_nb_res_early_CL_classif_70')
data_st_70 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res)
save(data_st_70, file = 'data_stacks/noNA_data_st_early_CL_classif_70')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_70 <-
data_st_70 %>%
blend_predictions()
model_st_70 <-
model_st_70 %>%
fit_members()
save(model_st_70, file = 'model_stacks/noNA_model_st_early_CL_classif_70')
# load('model_stacks/noNA_model_st_early_CL_classif_70')
set.seed(123)
data_test_70 <-
data_test_70 %>%
bind_cols(predict(model_st_70, .))
save(data_test_70, file = 'data_tests/noNA_data_test_early_CL_classif_70')
# confusion matrix for stacks
conf_mat_early_CL_classif_70 <- caret::confusionMatrix(data = data_test_70$.pred_class,
reference = data_test_70$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_70, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
# confusion matrix for base models
member_preds <-
data_test_70 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_70,
data_test_70,
members = TRUE
)
)
conf_mat_early_CL_classif_30
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
conf_mat_early_CL_classif_30
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
conf_mat_early_CL_classif_40
conf_mat_early_CL_classif_50
conf_mat_early_CL_classif_60
conf_mat_early_CL_classif_70
