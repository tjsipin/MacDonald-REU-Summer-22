<<<<<<< HEAD
<<<<<<< HEAD
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_50, file = 'data_stacks/noNA_data_st_early_CL_classif_50')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_50 <-
data_st_50 %>%
blend_predictions()
model_st_50 <-
model_st_50 %>%
fit_members()
save(model_st_50, file = 'model_stacks/noNA_model_st_early_CL_classif_50')
# load('model_stacks/noNA_model_st_early_CL_classif_50')
set.seed(123)
data_test_50 <-
data_test_50 %>%
bind_cols(predict(model_st_50, .))
save(data_test_50, file = 'data_tests/noNA_data_test_early_CL_classif_50')
# confusion matrix for stacks
conf_mat_early_CL_classif_50 <- caret::confusionMatrix(data = data_test_50$.pred_class,
reference = data_test_50$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_50, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# confusion matrix for base models
member_preds <-
data_test_50 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_50,
data_test_50,
members = TRUE
)
)
rm(list=ls())
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
# load and split the early data using imputed data
load('../../data/imp')
aad <- read.csv('../data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.6))[[1]] # PARAMETER
data <- data %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
=======
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
'te_forest', 'enn_mn_forest','Population','Year'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
>>>>>>> c21c61d2db2fb2a496853cebd90b86deacf084fb
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
split <- initial_split(data)
<<<<<<< HEAD
data_train <- training(split)
data_test_60_temp <- testing(split)
data_test_60 <-  (aad %>%
select(c(colnames(data_test_60_temp))))[data_test_60_temp %>% rownames(),] %>%
subset(!is.na(LST_Day)) %>%
<<<<<<< HEAD
subset(!is.na(SWOccurrence))%>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data_test_60$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_60$Cutaneous.Leishmaniasis < quantile, 0, 1))
=======
subset(!is.na(SWOccurrence))
data_test_70$pland_forest <- ifelse(is.na(data_test_70$pland_forest), 0, data_test_70$pland_forest)
data_test_70$te_forest <- ifelse(is.na(data_test_70$te_forest), 0, data_test_70$te_forest)
data_test_70$enn_mn_forest <- ifelse(is.na(data_test_70$enn_mn_forest), 0, data_test_70$enn_mn_forest)
data_test_70$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_70$Cutaneous.Leishmaniasis < quantile, 0, 1))
=======
<<<<<<< HEAD
=======
>>>>>>> 89ae9bc... rebasing?
data_train <- training(split)
data_test_70_temp <- testing(split)
Index_temp_70 <- as.numeric(rownames(data_test_70_temp))
data_test_70 <-  (aad %>%
dplyr::select(c(colnames(data_test_70_temp))))[Index_temp_70,]%>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
<<<<<<< HEAD
=======
=======
>>>>>>> large git reorg pt 1
data_train <- training(split)
data_test_30_temp <- testing(split)
Index_temp <- as.numeric(rownames(data_test_30_temp))
save(Index_temp, file = 'models/stacking/Index_temp_later_CL')
load(file = 'models/stacking/Index_temp_later_CL')
data_test_30 <-  (aad %>%
dplyr::select(c(colnames(data_test_30_temp))))[Index_temp,] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
<<<<<<< HEAD
>>>>>>> 2fb3d55... This commit seemed to have been done already
=======
>>>>>>> large git reorg pt 1
data_test_30$pland_forest <- ifelse(is.na(data_test_30$pland_forest), 0, data_test_30$pland_forest)
data_test_30$te_forest <- ifelse(is.na(data_test_30$te_forest), 0, data_test_30$te_forest)
data_test_30$enn_mn_forest <- ifelse(is.na(data_test_30$enn_mn_forest), 0, data_test_30$enn_mn_forest)
data_test_30$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_30$Cutaneous.Leishmaniasis < quantile, 0, 1))
<<<<<<< HEAD
>>>>>>> bc78f01... large git reorg pt 1
<<<<<<< HEAD
=======
data_test_70$pland_forest <- ifelse(is.na(data_test_70$pland_forest), 0, data_test_70$pland_forest)
data_test_70$te_forest <- ifelse(is.na(data_test_70$te_forest), 0, data_test_70$te_forest)
data_test_70$enn_mn_forest <- ifelse(is.na(data_test_70$enn_mn_forest), 0, data_test_70$enn_mn_forest)
data_test_70$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_70$Cutaneous.Leishmaniasis < quantile, 0, 1))
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
>>>>>>> c21c61d2db2fb2a496853cebd90b86deacf084fb
=======
>>>>>>> large git reorg pt 1
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
<<<<<<< HEAD
EVI + Precip + StableLights + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population, data = data_train) %>%
=======
EVI + Precip + AvgRad + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
=======
=======
>>>>>>> large git reorg pt 1
data_test_30 %>% names
data_test_30_temp %>% names
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI + EVI + Precip + AvgRad + SWOccurrence + pland_forest + te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
<<<<<<< HEAD
>>>>>>> bc78f01... large git reorg pt 1
<<<<<<< HEAD
=======
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + AvgRad + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
>>>>>>> c21c61d2db2fb2a496853cebd90b86deacf084fb
=======
>>>>>>> large git reorg pt 1
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
<<<<<<< HEAD
metric <- metric_set(sensitivity, accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
<<<<<<< HEAD
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'base_models/noNA_svm_res_early_CL_classif_60')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'base_models/noNA_xgb_res_early_CL_classif_60')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'base_models/noNA_rf_res_early_CL_classif_60')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'base_models/noNA_nb_res_early_CL_classif_60')
# load(file = 'base_models/noNA_svm_res_early_CL_classif_60')
# load(file = 'base_models/noNA_xgb_res_early_CL_classif_60')
# load(file = 'base_models/noNA_rf_res_early_CL_classif_60')
# load(file = 'base_models/noNA_nb_res_early_CL_classif_60')
data_st_60 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_60, file = 'data_stacks/noNA_data_st_early_CL_classif_60')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_60 <-
data_st_60 %>%
blend_predictions()
model_st_60 <-
model_st_60 %>%
fit_members()
save(model_st_60, file = 'model_stacks/noNA_model_st_early_CL_classif_60')
# load('model_stacks/noNA_model_st_early_CL_classif_60')
set.seed(123)
data_test_60 <-
data_test_60 %>%
bind_cols(predict(model_st_60, .))
save(data_test_60, file = 'data_tests/noNA_data_test_early_CL_classif_60')
# confusion matrix for stacks
conf_mat_early_CL_classif_60 <- caret::confusionMatrix(data = data_test_60$.pred_class,
reference = data_test_60$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_60, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# confusion matrix for base models
member_preds <-
data_test_60 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_60,
data_test_60,
members = TRUE
)
)
data_test_70 %>% tail()
rm(list=ls())
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
# load and split the early data using imputed data
load('../../data/imp')
aad <- read.csv('../data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.7))[[1]] # PARAMETER
data <- data %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year < 2014) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'StableLights', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population')) %>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
split <- initial_split(data)
data_train <- training(split)
data_test_70_temp <- testing(split)
data_test_70 <-  (aad %>%
select(c(colnames(data_test_70_temp))))[data_test_70_temp %>% rownames(),] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))%>%
filter(!is.na(pland_forest)) %>%
filter(!is.na(te_forest)) %>%
filter(!is.na(enn_mn_forest))
data_test_70$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_70$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + StableLights + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(sensitivity, accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'base_models/noNA_svm_res_early_CL_classif_70')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'base_models/noNA_xgb_res_early_CL_classif_70')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'base_models/noNA_rf_res_early_CL_classif_70')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'base_models/noNA_nb_res_early_CL_classif_70')
# load(file = 'base_models/noNA_svm_res_early_CL_classif_70')
# load(file = 'base_models/noNA_xgb_res_early_CL_classif_70')
# load(file = 'base_models/noNA_rf_res_early_CL_classif_70')
# load(file = 'base_models/noNA_nb_res_early_CL_classif_70')
data_st_70 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res)
save(data_st_70, file = 'data_stacks/noNA_data_st_early_CL_classif_70')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_70 <-
data_st_70 %>%
blend_predictions()
model_st_70 <-
model_st_70 %>%
fit_members()
save(model_st_70, file = 'model_stacks/noNA_model_st_early_CL_classif_70')
# load('model_stacks/noNA_model_st_early_CL_classif_70')
set.seed(123)
data_test_70 <-
data_test_70 %>%
bind_cols(predict(model_st_70, .))
save(data_test_70, file = 'data_tests/noNA_data_test_early_CL_classif_70')
# confusion matrix for stacks
conf_mat_early_CL_classif_70 <- caret::confusionMatrix(data = data_test_70$.pred_class,
reference = data_test_70$Cutaneous.Leishmaniasis,
positive = '1')
save(conf_mat_early_CL_classif_70, file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
# confusion matrix for base models
member_preds <-
data_test_70 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_70,
data_test_70,
members = TRUE
)
)
<<<<<<< HEAD
conf_mat_early_CL_classif_30
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
conf_mat_early_CL_classif_30
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
# load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_30')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_40')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_50')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_60')
load(file = 'confusion_matrices/noNA_conf_mat_early_CL_classif_70')
conf_mat_early_CL_classif_30
conf_mat_early_CL_classif_40
conf_mat_early_CL_classif_50
conf_mat_early_CL_classif_60
conf_mat_early_CL_classif_70
=======
load(file = 'models/stacking/conf_mat_later_CL_classif_30')
load(file = 'models/stacking/conf_mat_later_CL_classif_40')
load(file = 'models/stacking/conf_mat_later_CL_classif_50')
load(file = 'models/stacking/conf_mat_later_CL_classif_60')
load(file = 'models/stacking/conf_mat_later_CL_classif_70')
conf_mat_later_CL_classif_30
conf_mat_later_CL_classif_40
conf_mat_later_CL_classif_50
conf_mat_later_CL_classif_60
conf_mat_later_CL_classif_70
library(tidyverse)
library(pROC)
library(dplyr)
library(ggplot2)
library(plotROC)
load(file = 'models/stacking/data_test_later_CL_classif_30')
load(file = 'models/stacking/data_test_later_CL_classif_40')
load(file = 'models/stacking/data_test_later_CL_classif_50')
load(file = 'models/stacking/data_test_later_CL_classif_60')
load(file = 'models/stacking/data_test_later_CL_classif_70')
roc_30 <- roc(data_test_30$Cutaneous.Leishmaniasis,
data_test_30$.pred_class %>% as.numeric(),
print.auc = T, main = "AUC's of Percentiles in Later Data")
roc_40 <- roc(data_test_40$Cutaneous.Leishmaniasis,
data_test_40$.pred_class %>% as.ordered(),
print.auc = T)
roc_50 <- roc(data_test_50$Cutaneous.Leishmaniasis,
data_test_50$.pred_class %>% as.ordered(),
print.auc = T)
roc_60 <- roc(data_test_60$Cutaneous.Leishmaniasis,
data_test_60$.pred_class %>% as.ordered())
roc_70 <- roc(data_test_70$Cutaneous.Leishmaniasis,
data_test_70$.pred_class %>% as.ordered())
roc_list <- list('30th percentile' = roc_30,
'40th percentile' = roc_40,
'50th percentile' = roc_50,
'60th percentile' = roc_60,
'70th percentile' = roc_70)
# extract AUC
data.auc <- roc_list %>%
map(~tibble(AUC = .x$auc)) %>%
bind_rows(.id = 'name')
# generate labels
data.labels <- data.auc %>%
mutate(label_long = paste0(name, ' , AUC = ',
paste(round(AUC,2))),
label_AUC = paste0('AUC = ',
paste(round(AUC,2))))
pROC::ggroc(roc_list,
legacy.axes = F) +
scale_color_discrete(labels = data.labels$label_long)
# to get true levels of CL again
data <- read_csv('models/data/aad.csv')
=======
=======
metric <- metric_set(accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
>>>>>>> large git reorg pt 1
Index_temp
index_temp_train <- as.numeric(rownames(data_train))
index_temp_train
aad[index_temp_train]
aad[index_temp_train,]
aad[index_temp_train,] + aad[Index_temp,]
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30)
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(Year < 2018) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_30_temp <- testing(split)
Index_temp <- as.numeric(rownames(data_test_30_temp))
save(Index_temp, file = 'models/stacking/Index_temp_later_CL')
load(file = 'models/stacking/Index_temp_later_CL')
data_test_30 <-  (aad %>%
dplyr::select(c(colnames(data_test_30_temp))))[Index_temp,] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30)
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30) %>% rownames()
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30) %>% rownames() %>% as.numeric()
data_test_30_temp
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30)
anti_join(aad %>% subset(is.na(LST_Day)) %>% subset(is.na(SWOccurrence)), data_test_30, by = 'Cutaneous.Leishmaniasis')
anti_join(aad %>% subset(!is.na(LST_Day)) %>% subset(!is.na(SWOccurrence)), data_test_30, by = 'Cutaneous.Leishmaniasis')
data_test_30
data_train
split$id
split$id$id
split$in_id
split$out_id
?initial_split
split$id
split$data
split$data %>% dimm
split$data %>% dim
data %>% dim
split$in_id
split$in_id %>% dim
split$in_id %>% length
data_train %>% dim
split$out_id %>% length
split$out_id
split$in_id
data %>% rownames()
data %>% rownames() %>% as.numeric()
data_test_30 %>% rownames
data_test_30 %>% length
data_test_30 %>% dim()
data_test_30 %>% width
data_test_30 %>% nrow
split$in_id
split$in_id %>% length + data_test_30 %>% nrow
data %>% nrow
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(Year < 2018) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_30_temp <- testing(split)
Index_temp <- as.numeric(rownames(data_test_30_temp))
save(Index_temp, file = 'models/stacking/Index_temp_later_CL')
load(file = 'models/stacking/Index_temp_later_CL')
data_test_30 <-  (aad %>%
dplyr::select(c(colnames(data_test_30_temp))))[Index_temp,] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
data_test_30$pland_forest <- ifelse(is.na(data_test_30$pland_forest), 0, data_test_30$pland_forest)
data_test_30$te_forest <- ifelse(is.na(data_test_30$te_forest), 0, data_test_30$te_forest)
data_test_30$enn_mn_forest <- ifelse(is.na(data_test_30$enn_mn_forest), 0, data_test_30$enn_mn_forest)
data_test_30$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_30$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
split$in_id %>% length + data_test_30 %>% nrow
split$in_id %>% length
data_test_30 %>% nrow
split$in_id %>% length; data_test_30 %>% nrow
split$in_id %>% length; data_test_30 %>% nrow; split$in_id %>% length + data_test_30 %>% nrow
data_test_30_temp %>% length
data_test_30_temp %>% nrow
split$in_id %>% length; data_test_30 %>% nrow; split$in_id %>% length + data_test_30 %>% nrow; data_test_30_temp %>% nrow
data %>% rownames()
anti_join(data %>%
rownames() %>%
as.numeric(),
split$in_id)
data %>%
rownames() %>%
as.numeric()
split$in_id
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id)
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())
split$in_id
split$in_id %>% order()
split$in_id %>% order(decreasing = F)
split$in_id
split$in_id %>% order(decreasing = F)
split$in_id %>% sort(decreasing = F)
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame()) %>%
as.numeric()
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())$values
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[1]
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[[1]]
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[[[1]]]
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[[1]]
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame()) %>%
as.vector()
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[1,]
anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[,1]
testing_index = anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[,1]
testing_index == index_temp_train
testing_index == Index_temp
(testing_index == Index_temp) %>% summary
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
set.seed(123)
# load and split the later data using imputed data
load('./data/imp')
aad <- read_csv('models/data/aad.csv')
<<<<<<< HEAD
>>>>>>> bc78f01... large git reorg pt 1
<<<<<<< HEAD
=======
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'models/stacking/svm_res_later_CL_classif_70')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'models/stacking/xgb_res_later_CL_classif_70')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'models/stacking/rf_res_later_CL_classif_70')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'models/stacking/nb_res_later_CL_classif_70')
load(file = 'models/stacking/svm_res_later_CL_classif_70')
load(file = 'models/stacking/xgb_res_later_CL_classif_70')
load(file = 'models/stacking/rf_res_later_CL_classif_70')
load(file = 'models/stacking/nb_res_later_CL_classif_70')
data_st_70 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_70, file = 'models/stacking/data_st_later_CL_classif_70')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensembe member
model_st_70 <-
data_st_70 %>%
blend_predictions()
model_st_70 <-
model_st_70 %>%
fit_members()
save(model_st_70, file = 'models/stacking/model_st_later_CL_classif_70')
set.seed(123)
data_test_70 <- testing(split)
data_test_70 <-
data_test_70 %>%
bind_cols(predict(model_st_70, .))
save(data_test_70, file = 'models/stacking/data_test_later_CL_classif_70')
# confusion matrix for stacks
conf_mat_later_CL_classif_70 <- caret::confusionMatrix(data = data_test_70$.pred_class,
reference = data_test_70$Cutaneous.Leishmaniasis,
positive = '1')
conf_mat_later_CL_classif_70
save(conf_mat_later_CL_classif_70, file = 'models/stacking/conf_mat_later_CL_classif_70')
# confusion matrix for base models
member_preds <-
data_test_70 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_70,
data_test_70,
members = TRUE
)
)
load(file = 'models/stacking/conf_mat_later_CL_classif_30')
load(file = 'models/stacking/conf_mat_later_CL_classif_40')
load(file = 'models/stacking/conf_mat_later_CL_classif_50')
load(file = 'models/stacking/conf_mat_later_CL_classif_60')
load(file = 'models/stacking/conf_mat_later_CL_classif_70')
conf_mat_later_CL_classif_30
conf_mat_later_CL_classif_40
conf_mat_later_CL_classif_50
conf_mat_later_CL_classif_60
conf_mat_later_CL_classif_70
library(tidyverse)
library(pROC)
library(dplyr)
library(ggplot2)
library(plotROC)
load(file = 'models/stacking/data_test_later_CL_classif_30')
load(file = 'models/stacking/data_test_later_CL_classif_40')
load(file = 'models/stacking/data_test_later_CL_classif_50')
load(file = 'models/stacking/data_test_later_CL_classif_60')
load(file = 'models/stacking/data_test_later_CL_classif_70')
roc_30 <- roc(data_test_30$Cutaneous.Leishmaniasis,
data_test_30$.pred_class %>% as.numeric(),
print.auc = T, main = "AUC's of Percentiles in Later Data")
roc_40 <- roc(data_test_40$Cutaneous.Leishmaniasis,
data_test_40$.pred_class %>% as.ordered(),
print.auc = T)
roc_50 <- roc(data_test_50$Cutaneous.Leishmaniasis,
data_test_50$.pred_class %>% as.ordered(),
print.auc = T)
roc_60 <- roc(data_test_60$Cutaneous.Leishmaniasis,
data_test_60$.pred_class %>% as.ordered())
roc_70 <- roc(data_test_70$Cutaneous.Leishmaniasis,
data_test_70$.pred_class %>% as.ordered())
roc_list <- list('30th percentile' = roc_30,
'40th percentile' = roc_40,
'50th percentile' = roc_50,
'60th percentile' = roc_60,
'70th percentile' = roc_70)
# extract AUC
data.auc <- roc_list %>%
map(~tibble(AUC = .x$auc)) %>%
bind_rows(.id = 'name')
# generate labels
data.labels <- data.auc %>%
mutate(label_long = paste0(name, ' , AUC = ',
paste(round(AUC,2))),
label_AUC = paste0('AUC = ',
paste(round(AUC,2))))
pROC::ggroc(roc_list,
legacy.axes = F) +
scale_color_discrete(labels = data.labels$label_long)
# to get true levels of CL again
data <- read_csv('models/data/aad.csv')
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
=======
>>>>>>> large git reorg pt 1
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.4))[[1]] # PARAMETER
data <- data %>%
filter(Year > 2013) %>%
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
filter(Year < 2018) %>%
>>>>>>> bc78f01... large git reorg pt 1
=======
>>>>>>> 89ae9bc... rebasing?
=======
=======
filter(Year < 2018) %>%
>>>>>>> bc78f01... large git reorg pt 1
>>>>>>> 2fb3d55... This commit seemed to have been done already
=======
filter(Year < 2018) %>%
>>>>>>> large git reorg pt 1
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'AvgRad', 'SWOccurrence', 'pland_forest',
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
'te_forest', 'enn_mn_forest','Population'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
set.seed(123)
split_t <- initial_split(data)
training_t <- training(split_t)
testing_t <- testing(split_t)
mis_40 <- data_test_40 %>%
mutate(CL = testing_t$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
mis_40 <- data_test_40 %>%
mutate(CL = data_test_40_temp$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
knitr::opts_chunk$set(echo = T, cache = T, eval = T, results = 'show')
set.seed(123)
library(tidyverse)
library(tidymodels)
library(stacks)
aad <- read_csv('models/data/aad.csv')
load('./data/imp')
=======
=======
>>>>>>> large git reorg pt 1
'te_forest', 'enn_mn_forest','Population','Year'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
data$Year <- as.numeric(data$Year)
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_40_temp <- testing(split)
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[Index_temp,] %>%
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
data_test_40$pland_forest <- ifelse(is.na(data_test_40$pland_forest), 0, data_test_40$pland_forest)
data_test_40$te_forest <- ifelse(is.na(data_test_40$te_forest), 0, data_test_40$te_forest)
data_test_40$enn_mn_forest <- ifelse(is.na(data_test_40$enn_mn_forest), 0, data_test_40$enn_mn_forest)
data_test_40$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_40$Cutaneous.Leishmaniasis < quantile, 0, 1))
testing_index = anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[,1]
(testing_index == Index_temp) %>% summary
split$in_id %>% sort(decreasing = F)
(testing_index == Index_temp) %>% summary
testing_index
split$in_id %>% sort(decreasing = F)
testing_index = anti_join(data %>%
rownames() %>%
as.numeric() %>%
as.data.frame(),
split$in_id %>%
as.data.frame())[,1]
testing_index
<<<<<<< HEAD
>>>>>>> bc78f01... large git reorg pt 1
<<<<<<< HEAD
=======
'te_forest', 'enn_mn_forest','Population'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
set.seed(123)
split_t <- initial_split(data)
training_t <- training(split_t)
testing_t <- testing(split_t)
mis_40 <- data_test_40 %>%
mutate(CL = testing_t$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
mis_40 <- data_test_40 %>%
mutate(CL = data_test_40_temp$Cutaneous.Leishmaniasis) %>%
filter((data_test_40$Cutaneous.Leishmaniasis != data_test_40$.pred_class)) %>%
mutate(Case = which((data_test_40$.pred_class != data_test_40$Cutaneous.Leishmaniasis)))
knitr::opts_chunk$set(echo = T, cache = T, eval = T, results = 'show')
set.seed(123)
library(tidyverse)
library(tidymodels)
library(stacks)
aad <- read_csv('models/data/aad.csv')
load('./data/imp')
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
=======
>>>>>>> large git reorg pt 1
# helper packages
library(tidyverse)
library(tidymodels)
library(stacks)
set.seed(123)
# load and split the later data using imputed data
load('./data/imp')
aad <- read_csv('models/data/aad.csv')
quantile_data <- data %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(Cutaneous.Leishmaniasis)
quantile <- (quantile_data$Cutaneous.Leishmaniasis %>%
quantile(0.4))[[1]] # PARAMETER
data <- data %>%
filter(Year > 2013) %>%
filter(Year < 2018) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0) %>%
dplyr::select(c('Cutaneous.Leishmaniasis', 'LST_Day', # include LST_Night?
'NDVI', 'EVI', 'Precip',
'AvgRad', 'SWOccurrence', 'pland_forest',
'te_forest', 'enn_mn_forest','Population','Year'))
data$pland_forest <- ifelse(is.na(data$pland_forest), 0, data$pland_forest)
data$te_forest <- ifelse(is.na(data$te_forest), 0, data$te_forest)
data$enn_mn_forest <- ifelse(is.na(data$enn_mn_forest), 0, data$enn_mn_forest)
data$Cutaneous.Leishmaniasis <- as.factor(ifelse(data$Cutaneous.Leishmaniasis < quantile, 0, 1))
data$Year <- as.numeric(data$Year)
set.seed(123) # for reproducibility
aad <- aad %>%
filter(Year > 2013) %>%
filter(!is.na(Cutaneous.Leishmaniasis)) %>%
filter(Cutaneous.Leishmaniasis > 0)
split <- initial_split(data)
data_train <- training(split)
data_test_40_temp <- testing(split)
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
Index_temp_40 <- as.numeric(rownames(data_test_40_temp))
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[Index_temp_40,] %>%
=======
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[testing_index,] %>%
>>>>>>> bc78f01... large git reorg pt 1
<<<<<<< HEAD
=======
Index_temp_40 <- as.numeric(rownames(data_test_40_temp))
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[Index_temp_40,] %>%
>>>>>>> 89ae9bc... rebasing?
=======
>>>>>>> 2fb3d55... This commit seemed to have been done already
=======
data_test_40 <-  (aad %>%
dplyr::select(c(colnames(data_test_40_temp))))[testing_index,] %>%
>>>>>>> large git reorg pt 1
subset(!is.na(LST_Day)) %>%
subset(!is.na(SWOccurrence))
data_test_40$pland_forest <- ifelse(is.na(data_test_40$pland_forest), 0, data_test_40$pland_forest)
data_test_40$te_forest <- ifelse(is.na(data_test_40$te_forest), 0, data_test_40$te_forest)
data_test_40$enn_mn_forest <- ifelse(is.na(data_test_40$enn_mn_forest), 0, data_test_40$enn_mn_forest)
data_test_40$Cutaneous.Leishmaniasis <- as.factor(ifelse(data_test_40$Cutaneous.Leishmaniasis < quantile, 0, 1))
# use a 5-fold cross-validation
folds <- rsample::vfold_cv(data_train,
v = 5,
strata = Cutaneous.Leishmaniasis)
# set up a basic recipe
data_rec <-
recipe(Cutaneous.Leishmaniasis ~ LST_Day + NDVI +
EVI + Precip + AvgRad + SWOccurrence + pland_forest +
te_forest + enn_mn_forest + Population + Year, data = data_train) %>%
step_dummy(all_nominal() - all_outcomes()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_numeric())
# define a minimal workflow
data_wflow <-
workflow() %>%
add_recipe(data_rec)
# add metric
metric <- metric_set(accuracy)
# save assessment set predictions and workflow used to fit the resamples
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
# models: SVM, XGBoost, RF
## models to try: logistic regression
# toy model
log_reg_spec <-
logistic_reg() %>%
set_engine('glm')
log_reg_wflow <-
data_wflow %>%
add_model(log_reg_spec)
set.seed(123)
log_reg_res <-
fit_resamples(
log_reg_wflow,
resamples = folds,
metrics = metric,
control = ctrl_res
)
# define svm model using parsnip
svm_spec <-
svm_rbf(
cost = parsnip::tune(),
rbf_sigma = parsnip::tune(),
engine = 'kernlab',
mode = 'classification'
)
# add it to a workflow
svm_wflow <-
data_wflow %>%
add_model(svm_spec)
# tune cost and rbf_sigma and fit to the 5-fold cv
set.seed(123)
svm_res <-
tune_grid(
svm_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(svm_res, file = 'models/stacking/svm_res_later_CL_classif_40')
# define xgboost model using parsnip
set.seed(123)
xgb_spec <-
boost_tree(
mtry = tune(),
trees = tune(),
min_n = tune(),
tree_depth = tune(),
learn_rate = tune(),
loss_reduction = tune()
) %>%
set_engine('xgboost') %>%
set_mode('classification')
# add it to a workflow
xgb_wflow <-
data_wflow %>%
add_model(xgb_spec)
# tune mtry, trees, min_n, tree_depth, etc.
xgb_res <-
tune_grid(
xgb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(xgb_res, file = 'models/stacking/xgb_res_later_CL_classif_40')
#
# define rf model using parsnip
set.seed(123)
rf_spec <-
rand_forest(
mtry = tune(),
trees = tune(),
min_n = tune()
) %>%
set_engine('ranger') %>%
set_mode('classification')
# add it to a workflow
rf_wflow <-
data_wflow %>%
add_model(rf_spec)
# tune mtry, trees, min_n
rf_res <-
tune_grid(
rf_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(rf_res, file = 'models/stacking/rf_res_later_CL_classif_40')
#
library(discrim) # for engine = 'naivebayes' or 'klaR'
library(agua) # for engine = 'h2o'
# define nb model using parsnip
nb_spec <-
naive_Bayes(
mode = 'classification',
smoothness = tune(),
Laplace = tune(),
engine = 'naivebayes'
)
# add it to a workflow
nb_wflow <-
data_wflow %>%
add_model(nb_spec)
# tune smoothness and Laplace
nb_res <-
tune_grid(
nb_wflow,
resamples = folds,
grid = 5,
control = ctrl_grid
)
save(nb_res, file = 'models/stacking/nb_res_later_CL_classif_40')
load(file = 'models/stacking/svm_res_later_CL_classif_40')
load(file = 'models/stacking/xgb_res_later_CL_classif_40')
load(file = 'models/stacking/rf_res_later_CL_classif_40')
load(file = 'models/stacking/nb_res_later_CL_classif_40')
data_st_40 <-
stacks() %>%
add_candidates(xgb_res) %>%
add_candidates(rf_res) %>%
add_candidates(svm_res) %>%
add_candidates(nb_res)
save(data_st_40, file = 'models/stacking/data_st_later_CL_classif_40')
load('models/stacking/data_st_later_CL_classif_40')
# creating a model stack
## ready to evaluate how it is that we need to combine predictions from
## each candidate ensemble member
model_st_40 <-
data_st_40 %>%
blend_predictions()
model_st_40 <-
model_st_40 %>%
fit_members()
save(model_st_40, file = 'models/stacking/model_st_later_CL_classif_40')
load('models/stacking/model_st_later_CL_classif_40')
data_test_40 <-
data_test_40 %>%
bind_cols(predict(model_st_40, .))
save(data_test_40, file = 'models/stacking/data_test_later_CL_classif_40')
load(file = 'models/stacking/data_test_later_CL_classif_40')
# confusion matrix for stacks
conf_mat_later_CL_classif_40 <- caret::confusionMatrix(data = data_test_40$.pred_class, reference = data_test_40$Cutaneous.Leishmaniasis,positive = '1')
conf_mat_later_CL_classif_40
save(conf_mat_later_CL_classif_40, file = 'models/stacking/conf_mat_later_CL_classif_40')
# confusion matrix for base models
member_preds <-
data_test_40 %>%
dplyr::select(Cutaneous.Leishmaniasis) %>%
bind_cols(
predict(
model_st_40,
data_test_40,
members = TRUE
)
)
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
=======
conf_mat_later_CL_classif_40
>>>>>>> bc78f01... large git reorg pt 1
=======
>>>>>>> 89ae9bc... rebasing?
=======
=======
conf_mat_later_CL_classif_40
>>>>>>> bc78f01... large git reorg pt 1
>>>>>>> 2fb3d55... This commit seemed to have been done already
>>>>>>> c21c61d2db2fb2a496853cebd90b86deacf084fb
=======
conf_mat_later_CL_classif_40
>>>>>>> large git reorg pt 1
