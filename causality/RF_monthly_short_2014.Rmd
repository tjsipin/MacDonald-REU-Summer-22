---
title: "RF_monthly_short"
author: "TJ Sipin"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Libraries and Data

We try our random forest on the monthly data, taking only years 2014 to 2017. 2018 can work but there are some missing values for cutaneous leishmaniasis.

```{r cars}
library(randomForest)
library(ggplot2)
library(finalfit)
library(dplyr)
library(naniar)
library(readr)
library(tidyverse)
library(caret)
library(readr)
library(dplyr)
library(mlbench)
library(rsample)

rawdata <- read_csv('../data/monthly_short.csv')
```

```{r}
rawdata %>% 
  filter(Year %in% c(2014, 2015, 2016, 2017)) %>%
  filter(`Cutaneous Leishmaniasis` > 0) %>% 
  summary()

rawdata %>% 
  filter(Year %in% c(2014)) %>%
  filter(`Cutaneous Leishmaniasis` > 0) %>% 
  summary()
```


## Exploratory 

### Elementary summary of data
```{r pressure, echo=FALSE}
# remove unnecessary row counter
# data <- data %>% 
#   select(-c(...1)) %>% 
#   filter(Year %in% c(2014, 2015, 2016, 2017)) %>% 
#   rename(CL = `Cutaneous Leishmaniasis`)

data <- rawdata %>% 
  select(-c(...1)) %>% 
  filter(Year %in% c(2014)) %>% 
  rename(CL = `Cutaneous Leishmaniasis`) %>% 
  filter(CL > 0) 

data %>% summary
```

Notice that there are no missing values included in this data set.

## Random Forest

### Splitting CL into low- and high-risk

The 40th percentile was obtained using a sensitivity test in our stacked model. 

```{r}
quantile_data <- data %>% 
  filter(CL > 0) %>% 
  select(CL)

quantile <- (quantile_data$CL %>% 
  quantile(.4))[[1]]

data_fac <- data %>% 
  mutate(CL = case_when(CL < quantile ~ 'low',
                         CL >= quantile ~ 'high'))
```

### Data partitioning

```{r}
set.seed(123)

# data_sample <- sample_n(data, size = nrow(data) * 0.7)

split <- initial_split(data, prop = 0.7, strata = CL)
train <- training(split) %>% as.data.frame()
test <- testing(split)


x_train <- train[, c(1:4, 6:16)]
y_train <- train[, 5]
```


Code inspiration from https://machinelearningmastery.com/tune-machine-learning-algorithms-in-r/.

```{r}
set.seed(123)
# split <- initial_split(data, strata = CL) # CL used for stratified sampling
# training <- training(split)
# testing <- testing(split)

# rf <- randomForest(CL ~ ., data = train, proximity = T)

# Create model with default parameters 

control <- trainControl(method = 'repeatedcv',
                        number = 10, 
                        repeats = 3, 
                        search = 'random')

tunegrid <- expand.grid(.mtry = sqrt(ncol(data %>% select(-c(CL)))))
rf_random <- train(CL ~ ., data = data, method = 'rf',
                    metric = 'MAPE',
                    tuneGrid =  tunegrid,
                    trControl = control)
```

#### v2 Alogrithm Tools

```{r}
# Algorithm Tune (tuneRF)
bestmtry <- tuneRF(x = x_train, y = y_train, stepFactor = 5, improve = 10)

# save(bestmtry, file = 'rf_bestmtry') # save file

bestmtry
```

#### v3 Random Search

```{r}
set.seed(123)
control <- trainControl(method = 'repeatedcv',
                        number = 5, 
                        repeats = 3,
                        search = 'random')

rf_random <- train(CL ~ .,
                   data = train,
                   method = 'rf',
                   metric = 'RMSE',
                   tuneLength = 3,
                   trControl = control)

print(rf_random); plot(rf_random)
```

### The random forest

```{r, eval = F}
rf <- randomForest(CL ~ ., data = train,
                   mtry = 8, importance = T, localImp = T, strata = CL)

rf; plot(rf)

save(rf, file = 'monthly_short_rf_CL')
```

```{r}
# load('monthly_short_rf')

rf %>% varImpPlot()

# Population
CL_vs_Population_pP <- rf %>% partialPlot(x.var = Population,
                   pred.data = train)

save(CL_vs_Population_pP, file = 'plots/CL_vs_Population_pP')

# Standing Water Occurrence
CL_vs_SWOccurrence_pP <- rf %>% partialPlot(x.var = SWOccurrence,
                                            pred.data = train)

save(CL_vs_SWOccurrence_pP, file = 'plots/CL_vs_SWOccurrence_pP')

# Land Surface Temperature
CL_vs_LST_Day_pP <- rf %>% partialPlot(x.var = LST_Day,
                                            pred.data = train)

save(CL_vs_LST_Day_pP, file = 'plots/CL_vs_LST_Day_pP')

# Precipitation
CL_vs_Precip_pP <- rf %>% partialPlot(x.var = Precip,
                                            pred.data = train)

save(CL_vs_Precip_pP, file = 'plots/CL_vs_Precip_pP')

# Average Radiance
CL_vs_AvgRad_pP <- rf %>% partialPlot(x.var = AvgRad,
                                            pred.data = train)

save(CL_vs_AvgRad_pP, file = 'plots/CL_vs_AvgRad_pP')

# EVI
CL_vs_EVI_pP <- rf %>% partialPlot(x.var = EVI,
                                   pred.data = train)

save(CL_vs_EVI_pP, file = 'plots/CL_vs_EVI_pP')

# NDVI
CL_vs_NDVI_pP <- rf %>% partialPlot(x.var = NDVI,
                                   pred.data = train)

save(CL_vs_NDVI_pP, file = 'plots/CL_vs_NDVI_pP')

# pland forest
CL_vs_pland_forest_pP <- rf %>% partialPlot(x.var = pland_forest,
                                   pred.data = train)

save(CL_vs_pland_forest_pP, file = 'plots/CL_vs_pland_forest_pP')

# area_mn_forest
CL_vs_area_mn_forest_pP <- rf %>% partialPlot(x.var = area_mn_forest,
                                   pred.data = train)

save(CL_vs_area_mn_forest_pP, file = 'plots/CL_vs_area_mn_forest_pP')

# te_forest
CL_vs_te_forest_pP <- rf %>% partialPlot(x.var = te_forest,
                                   pred.data = train)

save(CL_vs_te_forest_pP, file = 'plots/CL_vs_te_forest_pP')

# enn_mn_forest
CL_vs_enn_mn_forest_pP <- rf %>% partialPlot(x.var = enn_mn_forest,
                                             pred.data = train)

save(CL_vs_enn_mn_forest_pP, file = 'plots/CL_vs_enn_mn_forest_pP')
# 
# ggplot() + 
#   geom_line(aes(x = CV_vs_SWOccurrence_pP$x,
#                 y = CV_vs_SWOccurrence_pP$y))
# 
# ggplot(train) + 
#   geom_point(aes(x = SWOccurrence,
#                  y = CL))
# ggplot(test) + 
#   geom_point(aes(x = SWOccurrence,
#                  y = CL))
```

```{r}
data %>% 
  mutate(Precip_SWO = Precip - SWOccurrence)
```



```{r}
rf %>% partialPlot(x.var = Precip,
                   pred.data = train)
```



```{r}

ggplot() + 
  geom_line(aes(x = CL_vs_SWOccurrence_pP[[1]],
                y = CL_vs_SWOccurrence_pP[[2]])) +
  xlab('Hi') + 
  ylab('Hey')

ggplot(train) +
  geom_point(aes(x = SWOccurrence,
                 y = CL))
ggplot(test) +
  geom_point(aes(x = SWOccurrence,
                 y = CL))

```

## Prediction and Calculate Performance Metrics

```{r}
# pred1 = predict(rf)
# library(ROCR)
# perf = prediction(pred1, train$CL)
# 
# # 1. Area under curve
# auc = performance(perf, 'auc')
# auc
# 
# # 2. True Positive and Negative Rate
# pred3 = performance(perf, 'tpr', 'fpr')
# 
# # 3. Plot the ROC curve
# plot(pred3, main = 'ROC Curve for RF',
#      col = 2, lwd = 2)
# abline(a = 0, b = 1, lwd = 2, lty = 2, col = 'gray')

test_df <- test %>% 
  mutate(prediction = predict(rf, test)) %>% 
  mutate(difference = CL - prediction) %>% 
  mutate(Index = rownames(test))

alpha = c(0.7, 0, 0.99)

ggplot(test_df) + 
  geom_line(aes(x = test_df['EVI'], 
                y = CL,
                color = 'true'),
            alpha = alpha[1]) + 
  geom_line(aes(x = test_df['EVI'],
                y = difference,
                color = 'difference'),
            alpha = alpha[2]) +
  geom_line(aes(x = test_df['EVI'],
                y = prediction,
                color = 'prediction'),
            alpha = alpha[3])
  
```

## Quantile RF
https://www.r-bloggers.com/2021/04/quantile-regression-forests-for-prediction-intervals/

```{r}
# LST_Day + NDVI + EVI + Precip + AvgRad + SWOccurrence +  pland_forest + enn_mn_forest + te_forest + area_mn_forest
set.seed(123)

library(tidyverse)
library(tidymodels)
rf_recipe <-
  recipe(
    CL ~ Population + LST_Day + NDVI + Precip + AvgRad + SWOccurrence +
      pland_forest + enn_mn_forest + te_forest + area_mn_forest,
    data = train) %>% 
  # step_corr(all_predictors()) %>% 
  # step_normalize(all_predictors(), -all_outcomes()) %>% 
  prep()

rf_testing <- rf_recipe %>% 
  bake(test)

rf_training <- juice(rf_recipe)

rf_model <- rand_forest(mtry = 3,
                        trees = 700) %>% 
  set_engine('ranger', importance = 'impurity',
             seed = 123, quantreg = TRUE) %>% 
  set_mode('regression') %>% 
  fit(CL ~ ., data = train %>% select(-c(Name, Code, Year, Month, EVI)))


# rf_model_2 <- rand_forest(mtry = 3,
#                           trees = 700) %>% 
#   set_engine('randomForest',
#              seed = 123, quantreg = TRUE) %>% 
#   set_mode('regression') %>% 
#   fit(CL ~ . - Month - Year, data = train)


rf_wf <- workflow() %>%
  add_model(rf_model) %>%
  add_recipe(rf_recipe) %>%
  fit(train %>% select(-c(Name, Code, Year, Month, EVI)))
```

```{r}
rf_model %>% 
  predict(rf_testing) %>% 
  bind_cols(rf_testing) %>% 
  metrics(truth = CL, estimate = .pred)
```


```{r}
preds_bind <- function(data_fit, lower = 0.1, upper = 0.9) {
  predict(
    rf_wf$fit$fit$fit,
    extract_recipe(rf_wf) %>% 
      bake(data_fit),
    type = 'quantiles',
    quantiles = c(lower, upper, 0.50)
  ) %>% 
    with(predictions) %>% 
    as_tibble() %>%
    set_names(paste0('.pred', c('_lower', '_upper', ''))) %>% 
    # mutate(across(contains('.pred'), ~10^.x)) %>%
    bind_cols(data_fit) %>% 
    select(contains('.pred'), CL, Population,
           LST_Day, NDVI, EVI, Precip, AvgRad, SWOccurrence,
           pland_forest, area_mn_forest, enn_mn_forest, te_forest)
}

rf_preds_test <- preds_bind(test)
```

Sample of prediction intervals
```{r}
set.seed(123)
rf_preds_test %>% 
  mutate(pred_interval = cut_number(CL, n = 0.01)) %>% 
  group_by(pred_interval) %>% 
  sample_n(1000) %>% 
  ggplot(aes(x = .pred)) +
  geom_point(aes(y = .pred, color = 'prediction interval')) +
  geom_errorbar(aes(ymin = .pred_lower, ymax = .pred_upper, color = 'prediction interval')) + 
  geom_point(aes(y = CL, color = 'actuals'),
             alpha = 0.7) + 
  scale_x_log10() +
  scale_y_log10()
```


## Performance

```{r}
rf_preds_train <- preds_bind(train)

bind_rows(
  mape(rf_preds_train, CL, .pred),
  mape(rf_preds_test, CL, .pred)) %>% 
  mutate(dataset = c('training', 'holdout')) %>% 
  gt::gt() %>% 
  gt::fmt_number('.estimate', decimals = 1)
```

```{r}
quantile_data <- data %>% 
  filter(CL > 0) %>% 
  select(CL)

quantile <- (quantile_data$CL %>% 
  quantile(.4))[[1]]

data_cat <- data %>% 
  mutate(CL = case_when(CL < quantile ~ 'low',
                         CL >= quantile ~ 'high') %>% 
           as_factor())

set.seed(123)

# data_sample <- sample_n(data, size = nrow(data) * 0.7)

split_cat <- initial_split(data_cat, prop = 0.7, strata = CL)
train_cat <- training(split_cat) %>% as.data.frame()
test_cat <- testing(split_cat)




library(tidyverse)
library(tidymodels)

rf_recipe <-
  recipe(
    CL ~ Population + LST_Day + NDVI + Precip + AvgRad + SWOccurrence +
      pland_forest + enn_mn_forest + te_forest + area_mn_forest,
    data = train_cat) %>% 
  prep()

rf_testing <- rf_recipe %>% 
  bake(test_cat)

rf_training <- juice(rf_recipe)

rf_model <- rand_forest(mtry = 3,
                        trees = 700) %>% 
  set_engine('ranger', importance = 'impurity',
             seed = 123) %>%
  set_mode('classification') %>% 
  fit(CL ~ ., data = train_cat %>% select(-c(Name, Code, Year, Month, EVI))) 

set.seed(123)

# rf_wf <- workflow() %>% 
#   add_model(rf_model) %>% 
#   add_recipe(rf_recipe) %>% 
#   fit(train_cat)

rf_model %>% 
  predict(rf_testing) %>% 
  bind_cols(rf_testing) %>% 
  metrics(truth = CL, estimate = .pred_class)
```

## DALEX

```{r}
library(DALEX)
library(plotly)
library(gridExtra)
library(archivist)
```

```{r}
target_as_int <- as.integer(test_cat$CL)
explainer_rf <- DALEX::explain(model = rf_model,
                        data = test_cat[,-5],
                        y = target_as_int,
                        label = 'Random Forest')
```

```{r}

plot(
model_profile(
  explainer = explainer_rf, 
  variables = c('te_forest',
                'enn_mn_forest',
                'area_mn_forest',
                'pland_forest',
                'SWOccurrence',
                'AvgRad',
                'Precip',
                'NDVI',
                'LST_Day',
                'Population'),
  N = 10),
geom = 'profiles'
)

```

```{r}
dep_Precip <- model_profile(explainer = explainer_rf,
                            variables = c('te_forest',
                                          'enn_mn_forest',
                                          'area_mn_forest',
                                          'pland_forest',
                                          'SWOccurrence',
                                          'AvgRad',
                                          'Precip',
                                          'NDVI',
                                          'LST_Day',
                                          'Population'),
                            type = 'conditional',
                            N = 10)
plot(dep_Precip, geom = 'profiles') %>% ggplotly()
```

```{r}
train_cat[c(2167,817),]
```

