---
title: "Deep Neural Network Classification"
author: "Lyndsey Umsted"
date: '2022-07-05'
output: html_document
---

## Introduction
Introducing a densely connected deep neural network with two hidden layers and an output layer

## Libraries
```{r}
install.packages("tensorflow")
install.packages("keras")
library(keras)
library(tensorflow)
install_tensorflow()
library(dplyr)
```


## Data
```{r}
aad <- read.csv("Annual_Amazon_Data.csv")
#view(aad)

cutaneous <- aad$Cutaneous.Leishmaniasis
mucosal <- aad$Mucosal.Leishmaniasis
visceral <- aad$Visceral.Leishmaniasis
new_data <- subset(aad, !is.na(cutaneous))
#View(new_data)
library(tidyverse)
library(dplyr)
#names(new_data)

## splitting the data into a before 2014 set and an after 2014 set

early_data <- new_data %>%
  filter(Year < 2014)%>%
  dplyr::select(-c(29:69))
later_data <- new_data %>%
  filter(Year > 2013) %>%
  dplyr::select(-c(29:69))

#names(early_data)

## removing unnecessary variables

early_data <- early_data %>%
  dplyr::select(-c("AvgRad"))
later_data <- later_data %>%
  dplyr::select(-c("StableLights")) %>%
  mutate(later_data$OptTemp_Obs <- as.numeric(later_data$OptTemp_Obs)) %>%
  mutate(later_data$Year <- as.numeric(later_data$Year)) %>%
  mutate(later_data$Population <- as.numeric(later_data$Population))

```


```{r, fig.width = 10, fig.height = 10}
later_data_small <- later_data %>%
  dplyr::select(c("Population", "Cutaneous.Leishmaniasis", "Dengue_Alb_OptTemp", "Dengue_Aeg_OptTemp", "Chik_Alb_OptTemp", "Chik_Aeg_OptTemp", "Zika_OptTemp", "Malaria_OptTemp", "LST_Day", "LST_Night", "OptTemp_Obs", "NDVI", "EVI", "Precip", "AvgRad", "SWOccurrence")) %>%
  na.omit(later_data_small) 
later_data_t <- later_data_small %>%
  filter(Cutaneous.Leishmaniasis > 0)%>%
  mutate(Cutaneous.Leishmaniasis = (Cutaneous.Leishmaniasis))
# pairs(later_data_small, labels = c("Year", "Population", "Cutaneous.Leishmaniasis","LST_Day", "LST_Night", "OptTemp_Obs", "NDVI", "EVI", "Precip", "AvgRad", "SWOccurrence"))
# library(ggplot2)
# library(GGally)
# ggpairs(data.frame(Year = later_data_small[,1], Population = later_data_small[,2], Cutaneous.Leishmaniasis = later_data_small[,3], LST_Day = later_data_small[,4], LST_Night = later_data_small[,5], OptTemp_Obs = later_data_small[,6], NDVI = later_data_small[,7], EVI = later_data_small[,8], Precip = later_data_small[,9], StableLights = later_data_small[,10], SWOccurrence = later_data_small[,11]), lower = list(continuous = wrap('points'), alpha = 0.3, size  = 0.2))
```


```{r}
library(dplyr)
summary(later_data_small$Cutaneous.Leishmaniasis[later_data_small$Cutaneous.Leishmaniasis > 0])
cat_df <- subset(later_data_small, later_data_small$Cutaneous.Leishmaniasis > 0)
cat_df$Cutaneous.Leishmaniasis <- cut(later_data_small$Cutaneous.Leishmaniasis[later_data_small$Cutaneous.Leishmaniasis > 0], breaks = c(0, 0.090114445 , 0.876904527, 10^3), labels = c("low", "moderate", "high")) # 25% 75% 100%

# cat_df$label <- NA
# cat_df$label[cat_df$Cutaneous.Leishmaniasis == "low"] <- 0
# cat_df$label[cat_df$Cutaneous.Leishmaniasis == "moderate"] <- 1
# cat_df$label[cat_df$Cutaneous.Leishmaniasis == "high"] <- 2

# cat_df$Year <- as.numeric(cat_df$Year)
cat_df$Population <- as.numeric(cat_df$Population)
cat_df$OptTemp_Obs <- as.numeric(cat_df$OptTemp_Obs)
cat_df$Cutaneous.Leishmaniasis <- as.numeric(cat_df$Cutaneous.Leishmaniasis)
cat_df$Dengue_Aeg_OptTemp <- as.numeric(cat_df$Dengue_Aeg_OptTemp)
cat_df$Dengue_Alb_OptTemp <- as.numeric(cat_df$Dengue_Alb_OptTemp)
cat_df$Chik_Alb_OptTemp <- as.numeric(cat_df$Chik_Alb_OptTemp)
cat_df$Chik_Aeg_OptTemp <- as.numeric(cat_df$Chik_Aeg_OptTemp)
cat_df$Zika_OptTemp <- as.numeric(cat_df$Zika_OptTemp)
cat_df$Malaria_OptTemp <- as.numeric(cat_df$Malaria_OptTemp)
```

```{r}
M <- cor(cat_df[,1:16])
library(corrplot)
corrplot(M, method = 'circle')
```



```{r, fig.width = 10, fig.height = 10}
plot(cat_df)
```

```{r}
library(rsample)

set.seed(1)
data_split <- initial_split(cat_df, strata = "Cutaneous.Leishmaniasis", prop = 0.8)

training <- training(data_split) %>%
  group_by(Cutaneous.Leishmaniasis) %>%
  sample_n(size = 2402)
testing <- testing(data_split) 

x_train <- as.matrix(training[,-2])
x_test <- as.matrix(testing[,-2])

y_train <- (as.numeric(training$Cutaneous.Leishmaniasis) - 1)
y_test <- (as.numeric(testing$Cutaneous.Leishmaniasis) - 1)
 
# training <- subset(training, select = -Cutaneous.Leishmaniasis)
# testing <- subset(testing, select = -Cutaneous.Leishmaniasis)

```

```{r}
library(keras)
# One hot encode training target values
cat_df.trainLabels <- to_categorical(y_train)

# One hot encode test target values
cat_df.testLabels <- to_categorical(y_test)

# Print out the iris.testLabels to double check the result
print(cat_df.testLabels)
```


```{r}
# create the model
# model <- lm(cat_df.trainLabels ~ .,data = as.data.frame(training))
model <- keras_model_sequential()
```

Add layers to the model:
```{r}
library(reticulate)
model %>% 
    layer_dense(units = 8, activation = 'relu', input_shape = c(15)) %>% 
    layer_dense(units = 3, activation = 'softmax')
```

```{r}
summary(model)

#get model configuration
get_config(model)

# Get layer configuration
get_layer(model, index = 1)

# List the model's layers
model$layers

# List the input tensors
model$inputs

# List the output tensors
model$outputs
```

```{r}
# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )
```


```{r}
# Fit the model 

# Store the fitting history in `history` 
history <- model %>% fit(
     x_train, 
     cat_df.trainLabels, 
     epochs = 200,
     batch_size = 5, 
     validation_split = 0.2
 )

# Plot the history
plot(history)
```




```{r}
# Plot the model loss of the training data
plot(history$metrics$loss, main="Model Loss", xlab = "epoch", ylab="loss", col="blue", type="l")

# Plot the model loss of the test data
lines(history$metrics$val_loss, col="green")

# Add legend
legend("topright", c("train","test"), col=c("blue", "green"), lty=c(1,1))
```


```{r}
# Plot the accuracy of the training data 
plot(history$metrics$acc, main="Model Accuracy", xlab = "epoch", ylab="accuracy", col="blue", type="l")

# Plot the accuracy of the validation data
lines(history$metrics$val_acc, col="green")

# Add Legend
legend("bottomright", c("train","test"), col=c("blue", "green"), lty=c(1,1))
```


```{r}
# Predict the classes for the test data
classes <- model %>% predict(x_test, batch_size = 128) %>% k_argmax()

# Confusion matrix
table(as.vector(y_test), as.vector(classes))
```

```{r}
# Evaluate on test data and labels
score <- model %>% evaluate(x_test, cat_df.testLabels, batch_size = 128)

# Print the score
print(score)
```

```{r}
# Initialize the sequential model
model <- keras_model_sequential() 

# Add layers to model
model %>% 
    layer_dense(units = 8, activation = 'relu', input_shape = c(15)) %>% 
    layer_dense(units = 5, activation = 'relu') %>% 
    layer_dense(units = 3, activation = 'softmax')

# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )

# Fit the model to the data
model %>% fit(
     x_train, cat_df.trainLabels, 
     epochs = 200, batch_size = 5, 
     validation_split = 0.2
 )

# Evaluate the model
score <- model %>% evaluate(x_test, cat_df.testLabels, batch_size = 128)

# Print the score
print(score)
```


```{r}
# Plot the model loss
plot(history$metrics$loss, main="Model Loss", xlab = "epoch", ylab="loss", col="blue", type="l")
lines(history$metrics$val_loss, col="green")
legend("topright", c("train","test"), col=c("blue", "green"), lty=c(1,1))

# Plot the model accuracy
plot(history$metrics$acc, main="Model Accuracy", xlab = "epoch", ylab="accuracy", col="blue", type="l")
lines(history$metrics$val_acc, col="green")
legend("bottomright", c("train","test"), col=c("blue", "green"), lty=c(1,1))
```


```{r}
# Initialize a sequential model
model <- keras_model_sequential() 

# Add layers to the model
model %>% 
    layer_dense(units = 28, activation = 'relu', input_shape = c(15)) %>% 
    layer_dense(units = 3, activation = 'softmax')

# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )

# Fit the model to the data
model %>% fit(
     x_train, cat_df.trainLabels, 
     epochs = 200, batch_size = 5, 
     validation_split = 0.2
 )

# Evaluate the model
score <- model %>% evaluate(x_test, cat_df.testLabels, batch_size = 128)

# Print the score
print(score)
```


```{r}
# Initialize the sequential model
model <- keras_model_sequential() 

# Add layers to the model
model %>% 
    layer_dense(units = 28, activation = 'relu', input_shape = c(15)) %>% 
    layer_dense(units = 3, activation = 'softmax')

# Compile the model
model %>% compile(
     loss = 'categorical_crossentropy',
     optimizer = 'adam',
     metrics = 'accuracy'
 )

# Save the training history in the history variable
history <- model %>% fit(
  x_train, cat_df.trainLabels, 
  epochs = 200, batch_size = 5, 
  validation_split = 0.2
 )

# Plot the model loss
plot(history$metrics$loss, main="Model Loss", xlab = "epoch", ylab="loss", col="blue", type="l")
lines(history$metrics$val_loss, col="green")
legend("topright", c("train","test"), col=c("blue", "green"), lty=c(1,1))

# Plot the model accuracy
plot(history$metrics$acc, main="Model Accuracy", xlab = "epoch", ylab="accuracy", col="blue", type="l")
lines(history$metrics$val_acc, col="green")
legend("bottomright", c("train","test"), col=c("blue", "green"), lty=c(1,1))
```


```{r}
model <- keras_model_sequential() 

# Build up your model by adding layers to it
model %>% 
    layer_dense(units = 8, activation = 'relu', input_shape = c(15)) %>% 
    layer_dense(units = 3, activation = 'softmax')

# Define an optimizer
sgd <- optimizer_sgd(lr = 0.01)

# Use the optimizer to compile the model
model %>% compile(optimizer=sgd, 
                  loss='categorical_crossentropy', 
                  metrics='accuracy')

# Fit the model to the training data
history <- model %>% fit(
     x_train, cat_df.trainLabels, 
     epochs = 200, batch_size = 5, 
     validation_split = 0.2
 )

# Evaluate the model
score <- model %>% evaluate(x_test, cat_df.testLabels, batch_size = 128)

# Print the loss and accuracy metrics
print(score)

# Plot the model loss
plot(history$metrics$loss, main="Model Loss", xlab = "epoch", ylab="loss", col="blue", type="l")
lines(history$metrics$val_loss, col="green")
legend("topright", c("train","test"), col=c("blue", "green"), lty=c(1,1))

# Plot the model accuracy
plot(history$metrics$acc, main="Model Accuracy", xlab = "epoch", ylab="accuracy", col="blue", type="l")
lines(history$metrics$val_acc, col="green")
legend("bottomright", c("train","test"), col=c("blue", "green"), lty=c(1,1))
```







